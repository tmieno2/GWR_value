Reply to Reviewer 1:

Major Concern

The data generating process (d.g.p.) assumptions maintained by the authors for all models is incorrect. Since the d.g.p. are wrong, generation of a “true” field for parameters is also wrong, which renders the model comparisons incorrect and the conclusions erroneous. There are other issues related to the Monte Carlo experimental design that are also problematic. I mention these problems, below.

Reply: We maintain that our dgp does not have any problem. Please see our arguments further below.

1. The authors generate the “true” site-specific parameters using a Gaussian random field. It doesn’t appear that the authors allowed for correlations between the model parameters. In practice, response parameters are typically correlated.

Reply: The simulated parameters are indeed correlated. We can provide the code that created them to the editor upon request. If they were not correlated, neither would have the true optimal EONR been spatially correlated, but it is correlated, as well.

2. If the authors want to compare the performance of competing estimators, then the correct d.g.p.’s for each model should be used to generate yield data. Each competing model would use the data from its challengers to estimate the parameters. These results would then be compared to the “true” parameter values. If you have three competing models, A, B, and C, you would have 6 comparisons. On the diagonal, you’d compare A with A, B with B, etc. This gives you a “type-I” error comparison. The other comparison would give you “type-II” error comparisons (i.e., using the wrong model to estimate yields from a competitor’s d.g.p.). These comparisons would show you how well a given estimator works when it is paired with the “wrong” d.g.p.

Reply: We think that the confusion here comes from failure to make our actual objective clear in the previous manuscript. We apologize. If our objective had been to evaluate the value of having the ability to apply GWR to data from on-farm precision experimentation, we would agree with you that we should have used the functional form of the true yield response function in our GWR estimations. We make clear in the revised manuscript (pages 4-5, lines 54-73) that our main objective is to point out the problem/danger of applying GWR assuming the quadratic functional form when the true yield data generating process follows the quadratic-plateau functional form, as is the case for many crop-input relationships like corn and nitrogen. We have endeavored to make this much clearer in the revision of the manuscript.

3. The autho’s choose a quadratic response with plateau model as the yield d.g.p model. Yet, the GWR and GAM models are linear-quadratic. Thus, the theoretical yield model is inconsistent with the one used to estimate the model parameters.

Reply: As mentioned above, that is the whole point of our paper. Again, we apologize for not making this clearer in the original manuscript. Previous studies that promoted the use of GWR for VRA recommendations used GWR assuming a quadratic form of the yield response function. But, a consensus has been reached in the agronomic literature that the corn-nitrogen relationship is better represented by the quadratic-plateau functional form. We feel confident that previous studies assumed the quadratic because non-linear GWR was not readily estimable using statistical packages available when the research behind those publications was conducted. Our paper points out the danger of estimating economically optimal, site-specific input application management by applying GWR with a mis-specified yield response model. This very important in the case of Trevisan et al.’s work (2021), because they touted GWR as a very promising way to generate very profitable VRA recommendations that could derive profits from VRA over $50/ha greater than could be obtained from economically optimal uniform rate application. Our finding indicates that using GWR with quadratic functional form has a strong tendency to significantly over-estimate the value of VRA over URA. Basically, the implication is that Tervisan, et al.’s numbers should be received with great caution. We believe strongly that this is an important message that needs to be established in the literature.

4. The authors use a sample of n=1 to compare estimator performance. What needs to be done is to run the MC some number of times (say, 1,000), to generate bias and mean squared error (MSE). One could find the MSE and bias in profitability estimates for each comparison.

Reply: We ran and reported one thousand simulations in the research behind our originally submitted manuscript, and we ran one thousand simulations in the research behind the revised manuscript. Please let us know if it is not abundantly clear in the revised manuscript (page 9, lines 166-167) that we are reporting the results of one thousand simulations.

5. See Leung, Y., Mei, C. L., & Zhang, W. X. (2000), Statistical tests for spatial nonstationarity based on the geographically weighted regression model. Environment and Planning A, 32(1), 9–32 for the GWR d.g.p. There are two ways to generate GWR yields for a MC simulation. The first generates GWR yields as: y* = (I – L)-1e, where L is the GWR “hat” matrix. You would choose a weighting kernel for GWR, L, and then draw e from, say a N(0, σ2) distribution. You would hold L fixed (it is “truth”) and then pull e* from this distribution 1,000 times to generate 1,000 data sets. Use these data sets to find estimates, and then use the estimates to calculate profitability. The second approach uses “true” GWR betas as a reference. Here, you need to find a known y (for example, from an experiment, or simulated as a spatial random field), and then simulate yields as y* = X(X’W(s)X)-1X’W(s)y + e*, with W(s) GWR weights. Similar procedures apply to “hybrid GWR” models, which allow some parameters to vary spatially while others are not. I have not worked out your GAM d.g.p., but the logic would be similar.

Reply: We apologize again for not making our objective clear in the original manuscript. Given the objective, which we have clarified above, the quadratic-plateau function has to be the true yield response function; after all, we are trying to examine the danger of applying GWR under the assumption of a quadratic functional form when the true functional form is quadratic-plateau, and so not linear in its coefficients, and so not readily estimable with current software packages provided GWR. The dgp you suggest cannot be applied to non-linear yield response functions. Third, there is no reason to generate data based on the GWR way. Our dgp can be used to represent site-specific yield-response functions that are just as valid (or invalid) as those generated by yours. Again, we are not testing the “pure ability” of GWR to estimate site-specific yield response functions. We are not writing a pure statistics paper. Our paper focuses on the application of GWR to data from on-farm precision experimentation, and is not just about GWR estimation accuracy.

6. Your use of the Gaussian random field you generated as “truth” (if the parameters were correlated), corresponds with a Bayesian kriging estimator, but not GWR.

Reply: For the reasons discussed above, we maintain that our procedures are valid. We have tried to make the narrative in our manuscript to discuss those procedures more clearly (pages 9-10, lines 155-168).

7. GWR kernels matters. You use a Gaussian kernel that assumes all observations are correlated. Kernels that are more parsimonious include the Epanechnikov and bi-square kernels, which are local, rather than global, smoothers. Yield response to inputs is probably more aptly modeled as local spatial processes or local moving averages, but not global ones.

Reply: Both Trevisan, et al. (2021) and Rakshit, et al. (2020) use Gaussian kernels. Therefore, we report results from of use Gaussian kernels as our main results. For other kernels, please see the supplementary appendix, in which we provide the results from using the Bi-square, Exponential, Boxcar, and Tri-cube kernels. Our most important qualitative findings are unchanged: when the true functional form of the yield response function is quadratic-plateau, applying assuming a quadratic yield response function significantly over-estimates its true value of using GWR to generate VRA recommendations. We were not able to test Epanechnikov kernel as none of the R and Python statistical packages that implement GWR does not offer it. However, since the Epanechnikov kernel is very similar to the Bi-square kernel, it is not hard to imagine that the results with the Epanechnikov kernel will be similar to that with the Bi-square kernel.

Minor issues:
I encourage the authors to undertake a through technical editing of the manuscript. In several places, the authors make assertions that should be backed up with references. Some examples are: Page 5, line 90; page 8, line 162. These are two examples, but there are more.

Page 1, line 10: incomplete sentence.
Page 1, line 13: delete “large”
Page 2, lune 27: delete “etc.”
Page 2, line 35: delete “efficient”
Page 2, line 37: delete “,” after methods
Page 3, line 47: insert “the” before development
Page 4, line 71: insert “,” after surprising
Page 8, line 161: “assumes”
Page 7, line 137. What needs to be rewritten????
Page 10, line 212: e_jk

Reply: Our significant revision of the paper’s Introduction has made points 1-6 above no longer pertinent. Items 7 through 10 are fixed.